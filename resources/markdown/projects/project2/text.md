# Deep learning in music

Following pioneering studies that first applied neural networks in the field of music information retrieval (MIR), this project applies feed forward neutral networks to retrieve boundaries in musical pieces, e.g., between chorus and verse. Detecting such segment boundaries is an important task in music structure analysis, a sub-domain of MIR. To
that end, we developed a framework to perform supervised learning on a representative music
data set containing structural annotations.  After optimizing our models with respect to various hyper-parameters, we find them to outperform others considerably. 
We visualized here  what one of our networks 'sees' when beeing provided by music.

Study in collaboration with [Jan Schl&uuml;ter](http://www.ofai.at/~jan.schlueter/) and [Thomas Grill](http://grrrr.org/) @OFAI, Vienna, 2014
