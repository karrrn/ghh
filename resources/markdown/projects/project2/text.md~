# Deep learning in music

Following pioneering studies that first applied neural networks in the field of music information retrieval (MIR), this project applies feed forward neutral networks to retrieve boundaries in musical pieces, e.g., between chorus and verse. Detecting such segment boundaries is an important task in music structure analysis, a sub-domain of MIR. To
that end, we developed a framework to perform supervised learning on a representative music
data set containing structural annotations.  After optimizing our models with respect to various hyper-parameters, we find them to outperform others considerably. We visualized here  which regions of the input are of highest
interest for our networks. As a result, we found all networks to concentrate on very similar time and frequency
bands.

Study in collaboration with [Jan Schl&ouml;ter](http://www.ofai.at/~jan.schlueter/) and [Thomas Grill](http://grrrr.org/) @OFAI, Vienna, 2014
